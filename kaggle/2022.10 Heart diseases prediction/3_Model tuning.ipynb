{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763e74a0-ca69-40d5-a935-9a9941ee83b1",
   "metadata": {},
   "source": [
    "# Подбор моделей и  их гиперпараметров\n",
    "\n",
    "Рассматриваются различные модели для классификации с параллельным подбором гиперпараметров. Большая часть блокнота ячеек не считается (смотри константу MODEL_SWITCHER), так как отдельные ячейки могут выполнятся долго. Расчет включается по мере интереса или необходимости. Результаты подбора гиперпараметров сохраняются в .pickle файлы. При запуске блокнота необходимо провести подбор с нуля!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715ca3c8-344f-4c70-916f-369d8e9ec433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902b60f3-7001-4e4d-bbff-feeed955beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mvsdist\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import phik\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5ec124-1bb9-456d-a005-902d9c9154e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "375cefe2-fdba-49a1-ad06-3829ba0f41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0715b581-9948-4cc4-b575-abaaa8a8bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb8ed403-da29-47f5-ba7f-0530d2de4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import RANDOM_SEED, TARGET_FEATURE, FIG_SIZES, DFS_NAME, SCORER, FEATURE_NAMES, OPTUNA_STUDY_NAME\n",
    "from utils import read, write, split, score, test_bt, get_pars_from_tune_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f1a4a5f-9f7d-433a-b633-a7587112ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEED_TUNE = False\n",
    "TUNE_CV = 3\n",
    "TUNE_THREADS = 1\n",
    "NUM_OF_TRIALS = 200\n",
    "\n",
    "MODEL_SWITCHER = list()\n",
    "# MODEL_SWITCHER.append('lr_1')\n",
    "# MODEL_SWITCHER.append('lr_2')\n",
    "# MODEL_SWITCHER.append('knn_1')\n",
    "# MODEL_SWITCHER.append('svc_1')\n",
    "# MODEL_SWITCHER.append('nbc_1')\n",
    "# MODEL_SWITCHER.append('cb_1')\n",
    "# MODEL_SWITCHER.append('cb_2')\n",
    "MODEL_SWITCHER.append('cb_3')\n",
    "# MODEL_SWITCHER.append('cb_cp_1')\n",
    "# MODEL_SWITCHER.append('rf_1')\n",
    "# MODEL_SWITCHER.append('rf_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14fd4fbe-e754-42e4-b4cc-7915cfd7a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = read(DFS_NAME)\n",
    "\n",
    "# delete unusefull features that was found on feature importance stage\n",
    "# features = read(FEATURE_NAMES)\n",
    "# dfs = [df[features + ([TARGET_FEATURE] if TARGET_FEATURE in df else [])] for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c090a6-f9a5-49aa-ba84-04926cc563ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, name, dfs=dfs, train_df=None, fitted=False, **kwargs):\n",
    "    _, train, *tests, end_test = dfs\n",
    "    if train_df is not None:\n",
    "        train = train_df\n",
    "    if not fitted:\n",
    "        model.fit(*split(train))\n",
    "    if len(tests) == 1:\n",
    "        print('bt test')\n",
    "        r = test_bt(model, tests[0])\n",
    "    else:\n",
    "        r = [score(model, test) for test in tests]\n",
    "    m, v, s = mvsdist(r)\n",
    "    return {'name': name, 'model': model.__class__.__name__} | {'train': score(model, train), 'test': m.mean(), 'test_sem': m.std()}\n",
    "\n",
    "def end_test_model(model, dfs=dfs):\n",
    "    return model.predict(dfs[-1])\n",
    "\n",
    "def tune(opt_study_name, objective, parallel=True, num_of_trials=NUM_OF_TRIALS, **kwargs):\n",
    "    if isinstance(parallel, bool):\n",
    "        threads = TUNE_THREADS if parallel else 1\n",
    "    else:\n",
    "        threads = parallel\n",
    "    threads = TUNE_THREADS if parallel else 1\n",
    "    opt_study_name = OPTUNA_STUDY_NAME(opt_study_name)\n",
    "    if opt_study_name.exists():\n",
    "        study = read(opt_study_name)\n",
    "    else:\n",
    "        study = optuna.create_study(sampler=TPESampler(), direction='maximize')\n",
    "    for _ in range(num_of_trials // (4 * threads)):\n",
    "        study.optimize(objective, n_trials=4*threads, n_jobs=threads)\n",
    "        write(opt_study_name, study)\n",
    "        print('study is saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "351a2f26-d91c-473b-a963-316c1933a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_to_del_by_correlation(pc, edge):\n",
    "    i, j = np.indices((pc.shape[0], pc.shape[0]))\n",
    "    c = abs(pc.values) > edge\n",
    "    corr = sorted(map(sorted, zip(pc.index[i[c]], pc.index[j[c]])))\n",
    "    corr = set([(x, y) for x, y in corr if x != y])\n",
    "    deleted = []\n",
    "    for x, y in corr:\n",
    "        if x in deleted or y in deleted:\n",
    "            continue\n",
    "        deleted.append(max([x, y], key=len))\n",
    "    return sorted(deleted)\n",
    "\n",
    "def col_deleter(cols):\n",
    "    def temp(df, *args):\n",
    "        return df.drop(columns=list(cols))\n",
    "    return FunctionTransformer(temp)\n",
    "\n",
    "def col_deleter_pipe(model, cols):\n",
    "    return Pipeline([('col_deleter', col_deleter(cols)), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e980919-87b4-4cd2-bae6-b471117eb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "res = []\n",
    "def test(*args, **kwargs):\n",
    "    res.append(test_model(*args, **kwargs))\n",
    "    return pd.DataFrame(res[-1:]), args[0]\n",
    "\n",
    "def model_preparing(name, model_class, objective, common_param=dict(), models=models, **kwargs):\n",
    "    if name in MODEL_SWITCHER:\n",
    "        if NEED_TUNE: tune(name, objective, **kwargs)\n",
    "        params = get_pars_from_tune_res(name, **kwargs)\n",
    "        r = Parallel(n_jobs=TUNE_THREADS)(delayed(test)(model, name, **kwargs) for model, name in [(model_class(**(common_param | param)), f'{name}_{i}') for i, param in enumerate(params)])\n",
    "        models += [x[1] for x in r]\n",
    "        display(pd.concat([x[0] for x in r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58d5632c-cfbc-4622-8b78-4bc62bd2b4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bt test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>test_sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.784163</td>\n",
       "      <td>0.795069</td>\n",
       "      <td>0.002956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name               model     train      test  test_sem\n",
       "0  lr_1  LogisticRegression  0.784163  0.795069  0.002956"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 673 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_SEED)\n",
    "t, model = test(model, 'lr_1')\n",
    "models.append(model)\n",
    "display(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1711fc3-6095-41bd-98b7-15a049c2034e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.47 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'knn_1'\n",
    "model_class = KNeighborsClassifier\n",
    "def param_filter(param):\n",
    "    if param['algorithm'] in ['ball_tree', 'kd_tree'] and param['metric'] in ['cosine','nan_euclidean']:\n",
    "        param['metric'] = 'euclidean'\n",
    "    return param\n",
    "\n",
    "def objective(trial):\n",
    "    param = {'n_neighbors': trial.suggest_int('n_neighbors', 3, 30),\n",
    "             'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "             'algorithm': trial.suggest_categorical('algorithm', ['ball_tree', 'kd_tree', 'brute'])}\n",
    "    param['metric'] = trial.suggest_categorical('metric', ['cityblock', 'cosine', 'euclidean'])\n",
    "    if param['algorithm'] in ['ball_tree', 'kd_tree']:\n",
    "        param['leaf_size'] = trial.suggest_int('leaf_size', 10, 50)\n",
    "    param = param_filter(param)\n",
    "    model = model_class(**param)\n",
    "    res = cross_val_score(model, *split(dfs[1]), scoring=SCORER, cv=TUNE_CV, verbose=0)\n",
    "    return np.mean(res)\n",
    "\n",
    "model_preparing(name, model_class, objective, param_filter=param_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "994182fd-997a-4e28-9266-3dd8b6d43570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'svc_1'\n",
    "common_param = {'C': 0.01, 'verbose': 0, 'probability': True, 'random_state': RANDOM_SEED}\n",
    "model_class = SVC\n",
    "df = dfs[1].sample(10000)\n",
    "\n",
    "def objective(trial):\n",
    "    param = {'kernel': trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "             'shrinking': trial.suggest_categorical('shrinking', [True, False]),}\n",
    "    if param['kernel'] == 'poly':\n",
    "        param['degree'] = trial.suggest_int('degree', 1, 6)\n",
    "    if param['kernel'] in ['poly', 'rbf', 'sigmoid']:\n",
    "        param['gamma'] = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    if param['kernel'] in ['poly', 'sigmoid']:\n",
    "        param['coef0'] = trial.suggest_float('coef0', 0, 10)\n",
    "    model = model_class(**(common_param | param))\n",
    "    res = cross_val_score(model, *split(df), scoring=SCORER, cv=TUNE_CV, verbose=0)\n",
    "    return np.mean(res)\n",
    "\n",
    "model_preparing(name, model_class, objective, common_param, train_df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5938fbb8-9a6c-4a9b-8cf6-f84108a82ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bt test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>test_sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb_3_0</td>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.809533</td>\n",
       "      <td>0.804583</td>\n",
       "      <td>0.003008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name               model     train      test  test_sem\n",
       "0  cb_3_0  CatBoostClassifier  0.809533  0.804583  0.003008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'cb_3'\n",
    "cat_features = list(dfs[0].select_dtypes(include='category').columns)\n",
    "common_param = {'verbose': 0, 'random_state': RANDOM_SEED,\n",
    "                'cat_features': cat_features,}\n",
    "model_class = CatBoostClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    param = {'objective': trial.suggest_categorical('objective', ['Logloss', 'CrossEntropy']),\n",
    "             'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.01, 0.12),\n",
    "             'depth': trial.suggest_int('depth', 4, 12),\n",
    "             'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "             'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS'])}\n",
    "    param['iterations'] = trial.suggest_int('iterations', 500, 2000)\n",
    "    # param['grow_policy'] =  trial.suggest_categorical('grow_policy', ['Lossguide', 'SymmetricTree', 'Depthwise'])\n",
    "    param['leaf_estimation_backtracking'] =  trial.suggest_categorical('leaf_estimation_backtracking', ['AnyImprovement', 'No'])\n",
    "    param['l2_leaf_reg'] = trial.suggest_float('l2_leaf_reg', 0.1, 20)\n",
    "\n",
    "    if param['bootstrap_type'] == 'Bayesian':\n",
    "        param['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "    elif param['bootstrap_type'] == 'Bernoulli':\n",
    "        param['subsample'] = trial.suggest_float('subsample', 0.1, 1)\n",
    "    trial.set_user_attr('param', param)\n",
    "    trial.set_user_attr('common_param', common_param)\n",
    "    res = cross_val_score(model_class(**(common_param | param)),\n",
    "                          *split(dfs[1]), scoring=SCORER, cv=TUNE_CV, verbose=0)\n",
    "    return np.mean(res)\n",
    "\n",
    "model_preparing(name, model_class, objective, common_param, parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46aecef8-6871-4e45-9102-61401cfa9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "opt_study_name = OPTUNA_STUDY_NAME(name)\n",
    "if opt_study_name.exists():\n",
    "    old_params = read(opt_study_name).best_params\n",
    "    name = 'cb_cp_1'\n",
    "\n",
    "    def objective(trial):\n",
    "        old_params |= {'depth': trial.suggest_int('depth', 4, 12),\n",
    "                       'iterations': trial.suggest_int('iterations', 500, 2000)}\n",
    "        \n",
    "        pars_to_tune = ['colsample_bylevel', 'l2_leaf_reg']\n",
    "        if 'bootstrap_type' in old_params:\n",
    "            if old_params['bootstrap_type'] == 'Bayesian':\n",
    "                pars_to_tune.append('bagging_temperature')\n",
    "            elif old_params['bootstrap_type'] == 'Bernoulli':\n",
    "                pars_to_tune.append('subsample')\n",
    "        \n",
    "        eval_fun = (lambda param, df=dfs[1], model_class=model_class, cv=TUNE_CV, scoring=SCORER:\n",
    "                    cross_val_score(model_class(**param), *split(df), scoring=scoring, cv=cv, verbose=0))\n",
    "        def obj(vals, pars_to_tune=pars_to_tune, eval_fun=eval_fun,\n",
    "                old_params=old_params, common_param=common_param):\n",
    "            res = np.mean(eval_fun(common_param | old_params | dict(zip(pars_to_tune, vals))))\n",
    "            print(round(res, 4), end=', ')\n",
    "            return res\n",
    "        res = minimize(obj, [old_params[x] for x in pars_to_tune], method='Nelder-Mead',\n",
    "                       tol=1e-3, options={'maxiter': 100, 'fatol': 1e-4, 'disp': True})\n",
    "        trial.set_user_attr('param', old_params | dict(zip(pars_to_tune, res.x)))\n",
    "        trial.set_user_attr('common_param', common_param)\n",
    "        print()\n",
    "        return -res.fun\n",
    "\n",
    "    model_preparing(name, model_class, objective, common_param, parallel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "508c5030-b002-4075-979f-12f8e4df8ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "name = 'rf_2'\n",
    "common_param = {'random_state': RANDOM_SEED, 'class_weight': 'balanced'}\n",
    "model_class = RandomForestClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 100)\n",
    "    model = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, **common_param)\n",
    "    res = cross_val_score(model, *split(dfs[1]), scoring=SCORER, cv=TUNE_CV, verbose=0)\n",
    "    return np.mean(res)\n",
    "\n",
    "model_preparing(name, model_class, objective, common_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb13eb06-1cef-4952-a83e-cdc704124e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model = StackingClassifier([(str(i), model) for i, model in enumerate(models)],\n",
    "#                            final_estimator=LogisticRegression(max_iter=1000),\n",
    "#                            cv='prefit', n_jobs=TUNE_THREADS, passthrough=False)\n",
    "# t, model = test(model, 'sc_1', fitted=False)\n",
    "# models.append(model)\n",
    "# display(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
