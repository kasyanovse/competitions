{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0867c99-d7a4-45fd-8ebb-d3a7ec2fc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import nan\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from multiprocessing import Pool\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a10deb-0d3c-46d3-93d2-c991d77f3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40dde662-d47f-441f-b7f2-137409875ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ca967f8-cd2c-4933-b729-d7385980fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load import read_data, read, write, get_full_prepared_data_with_upsample\n",
    "from processing import start_processing, family_of_knn_features\n",
    "from parameters import RANDOM_SEED, SCORERS, TARGET_FEATURE, TEST_SIZE, THREADS, TARGET_REPLACER, INVERSE_TARGET_REPLACER\n",
    "from preparing import (MyOheHotEncoder, MyOrdinalEncoder, MyMinMaxScaler, ColumnsSorter,\n",
    "                       EmptyColFiller, MyPolynomialFeatures, ordinal_encoding, one_hot_encoding,\n",
    "                       col_cutter, col_retainer)\n",
    "from model_preparing import CBC, ConsecutiveEstimator, StackEstimator\n",
    "from tuning import try_each_col, try_wo_each_col, try_cols_in_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9959d5f-fa22-4330-b3c4-8cc2653f7da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('display.max_info_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6067698-54bf-4417-9ee6-aa4a74d01f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f, ft, fp = get_full_prepared_data_with_upsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedbf0aa-bad5-453f-97fd-5529d3f17a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get(val, col, ft=ft):\n",
    "#     res = []\n",
    "#     for x1, x2 in ft:\n",
    "#         f = x1[col] == val\n",
    "#         res.append((x1[f].drop(columns=[col]), x2[f]))\n",
    "#     return res\n",
    "\n",
    "# col = 'start_year'\n",
    "# for col in ('start_year', 'faculty', 'same_group_target'):\n",
    "#     res = []\n",
    "#     for val in ft[0][0][col].unique():\n",
    "#         res.append({'val': val} | CBC().eval_on_test(get(val, col)))\n",
    "#     print(col)\n",
    "#     display(pd.DataFrame(res).drop(columns='model').sort_values('std'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd377496-e928-4dad-8a41-e0ba9704e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# class TestModel(CommonEstimator):\n",
    "#     def __init__(self):\n",
    "#         self.fitted = False\n",
    "#         self.col = 'same_group_target'\n",
    "#         self.filt = lambda x: x[self.col] != 0\n",
    "#         self.clear_cols = lambda x: x.drop(columns=[self.col])\n",
    "    \n",
    "#     def fit(self, x, y):\n",
    "#         filt = self.filt(x)\n",
    "#         x = self.clear_cols(x)\n",
    "#         self.model = CBC()\n",
    "#         self.model.fit(x[filt], y[filt].replace(0, 1))\n",
    "#         return self\n",
    "    \n",
    "#     def predict(self, x, y=None):\n",
    "#         filt = self.filt(x)\n",
    "#         x = self.clear_cols(x)\n",
    "#         f_index = filt[filt].index\n",
    "#         y = pd.Series(0, x.index)\n",
    "#         y0 = pd.Series(self.model.predict(x[filt]), index=f_index)\n",
    "#         y[f_index] = y0\n",
    "#         return y.astype(int)\n",
    "\n",
    "# model = TestModel()\n",
    "# display(pd.DataFrame([model.eval_on_test(ft)]))\n",
    "# predict_on_test(model, ft, fp, refit=False)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db108ecb-7035-4ecc-8b85-1747d0473d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# class ConsecEstimator():\n",
    "#     def __init__(self, model_class):\n",
    "#         self.model_class = model_class\n",
    "#         self.replacer = [{2: 1}, {1: 0, 2: 1}]\n",
    "#         self.invercer = [{v: k for k, v in x.items()} for x in self.replacer]\n",
    "\n",
    "#     def fit(self, x, y):\n",
    "#         self.model = (self.model_class(), self.model_class())\n",
    "#         self.model[0].fit(x, y.replace(self.replacer[0]))\n",
    "#         self.model[1].fit(x[y != 0], y[y != 0].replace(self.replacer[1]))\n",
    "#         return self\n",
    "\n",
    "#     def predict(self, x, y=None):\n",
    "#         res_1 = pd.Series(self.model[0].predict(x).squeeze(), index=x.index)\n",
    "#         temp = res_1 != 0\n",
    "#         res_2 = pd.Series(self.model[1].predict(x[temp]).squeeze(), index=x[temp].index)\n",
    "#         res_1[x[temp].index] = res_2.replace(self.invercer[1])\n",
    "#         return res_1.values\n",
    "\n",
    "# a = ConsecEstimator(CBC)\n",
    "# pd.DataFrame([eval_pipe(a, ft)])\n",
    "# #predict_on_test(a, ft, fp, refit=True)\n",
    "# #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff569f8b-9149-4e45-b328-ff9a437a2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from optuna.samplers import TPESampler\n",
    "\n",
    "# x, y = ft[0][0], ft[0][1].replace(2, 1)\n",
    "# for col in x.columns:\n",
    "#     x[col] = x[col].astype(float)\n",
    "\n",
    "# def objective(trial):\n",
    "#     n_estimators = trial.suggest_int(\"n_estimators\", 10, 500)\n",
    "#     max_depth = trial.suggest_int(\"max_depth\", 2, 20)\n",
    "#     model = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators)\n",
    "\n",
    "#     score = cross_val_score(model, x, y, cv=3, scoring=SCORERS[0])\n",
    "#     return score.mean()\n",
    "\n",
    "# study = optuna.create_study(sampler=TPESampler(), direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae313ccd-796e-4943-bebf-6a3e97cfdfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# a = CBC()\n",
    "# pd.DataFrame([a.eval_on_test(ft)])\n",
    "# # predict_on_test(a, ft, fp, refit=True)\n",
    "# # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c30af9a-8b37-4561-8b6f-75e9bed083ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cols_base = ['condition', 'faculty', 'start_year', 'start_year_val', 'mean_mark_type2', 'city', 'birthday_year', 'school_type', 'mean_mark', 'region', 'diff_between_school_n_start', 'has_not_family', 'gender', 'mean_mark_add1', 'mean_mark_add2', 'country', 'relativies_country', 'language', 'school', 'school_location']\n",
    "cols_add = [tuple(),\n",
    "            ('group_code', ),\n",
    "            ('group_code_num', ),\n",
    "            ('group_code_add_1', 'group_code_add_2', 'group_code_add_3', 'group_code_add_4',),\n",
    "            ('k_5', ),\n",
    "            ('same_group_target', ),\n",
    "            ('same_group_target', 'group_code'),]\n",
    "cols = [list(x) + cols_base for x in cols_add]\n",
    "cols = [[y for y in x if y in f.columns] for x in cols]\n",
    "models = [CBC(transformers=[col_retainer(x)]) for x in cols]\n",
    "res = []\n",
    "# res = [x.test(ft) for x in models]\n",
    "# pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d0634-bfb8-431e-8f21-a11ac6c7e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linm = LogisticRegression(C=0.01, max_iter=1000, class_weight='balanced')\n",
    "model = StackEstimator(models, linm)\n",
    "res.append(model.test(ft))\n",
    "pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab25cb4-b02a-4f18-b9f6-ad2fb2205e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_final(ft, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf22369-ef0c-4b01-9ed7-8f6cae50f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = CBC()\n",
    "# m.test(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd95be-cc72-46a7-a3df-7ddbe729442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.utils.estimator_checks as a\n",
    "# a.check_estimator(CBC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55251e-df6f-4c74-9bda-b35542dcb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # models[0].fit(*ft[0])\n",
    "# models[0]._estimator_type\n",
    "# models[0].get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae937c-4c58-4ded-b115-8ae64a46f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# get_cf = lambda x: list(x.select_dtypes(include='category').columns)\n",
    "# cat_features = get_cf(ft[0][0])\n",
    "# classes_count = len(ft[0][1].unique())\n",
    "# # res = [fast_catboost(ft),\n",
    "# #        consecutive_prediction(fast_catboost, ft),\n",
    "# #        bagging_prediction(fast_catboost, ft)]\n",
    "# # res = [fast_catboost(ft),\n",
    "# #        consecutive_prediction(fast_catboost, ft)]\n",
    "# temp_cols_1 = ['same_group_target', 'condition', 'faculty', 'group1_code_add_3', 'start_year', 'birthday_year', 'num_group_code', 'num_group_code_rexp3_scale_fun', 'num_group_code_exp3_scale_fun', 'sub_group_code_5', 'num_group_code_exp5_scale_fun', 'num_group_code_expexp_scale_fun', 'mean_mark_type2', 'num_group_code_sqrt_scale_fun', 'num_group_code_rexp5_scale_fun', 'group1_code_add_2', 'school_type', 'num_group_code_r_scale_fun', 'relativies_country', 'num_group_code_2_scale_fun', 'region', 'language', 'group1_code_add_1', 'city', 'country', 'school_location', 'school', 'group1_code_add_4', 'sub_group_code_20', 'mean_mark_sin_scale_fun']\n",
    "# add_kwargs = [{'_transformers': [x]} for x in [col_retainer(temp_cols_1),\n",
    "#                                                col_cutter(['same_group_target']),\n",
    "#                                                col_cutter(['same_group_target', 'group_code']),\n",
    "#                                                col_cutter([x for x in ft[0][0].columns if 'scale_fun' in x]),\n",
    "#                                                col_cutter([x for x in ft[0][0].columns if 'scale_fun' in x or 'group_code' in x])]] + [dict()]\n",
    "# add_cat_features = [get_cf(deepcopy(x['_transformers'][0]).fit_transform(ft[0][0])) for x in add_kwargs if len(x) > 0] + [cat_features]\n",
    "# add_kwargs = [x | {'cat_features': y, 'classes_count': } for x, y in zip(add_kwargs, add_cat_features)]\n",
    "#res = [fast_catboost(ft, **kwargs) for kwargs in add_kwargs]\n",
    "#res = [fast_catboost(**kwargs) for kwargs in add_kwargs]\n",
    "#res = [simple_stacking_catboost([x['model'] for x in res], ft)]\n",
    "#res += [consecutive_prediction(fast_catboost, ft, **kwargs) for kwargs in add_kwargs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf474c0-49cf-4cb7-968f-31cdcd38ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(res).drop(columns=['model']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9f34a-932e-4e68-82c3-32b690984517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for ires in res:\n",
    "#     predict_on_test(ires['model'], ft, fp, refit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
